diff -Naur ARToolKit/Configure ARToolKit-Freenect/Configure
--- ARToolKit/Configure	2006-12-06 01:37:23.000000000 +0100
+++ ARToolKit-Freenect/Configure	2012-06-13 03:28:41.834680705 +0200
@@ -10,6 +10,7 @@
       lib/SRC/VideoLinuxV4L lib/SRC/VideoSGI \
       lib/SRC/VideoMacOSX \
       lib/SRC/VideoGStreamer \
+      lib/SRC/VideoOpenKinect \
       lib/SRC/ARvrml \
       util \
       util/calib_camera2 util/calib_cparam util/calib_distortion \
@@ -19,7 +20,7 @@
       examples/loadMultiple  examples/modeTest  examples/multi  examples/optical  \
       examples/paddle examples/paddleDemo examples/paddleInteraction examples/range \
       examples/relation examples/simple examples/simple2 examples/simpleLite \
-      examples/twoView examples/simpleVRML \
+      examples/twoView examples/simpleVRML examples/openKinect \
       "
 
 SED=/tmp/SED.$$
@@ -36,6 +37,7 @@
     echo "  3: Digital Video Camcoder through IEEE 1394 (DV Format)"
     echo "  4: Digital Video Camera through IEEE 1394 (VGA NONCOMPRESSED Image Format)"
     echo "  5: GStreamer Media Framework"
+    echo "  6: OpenKinect (libfreenect)"
     echo -n "Enter : "
     read ANS
     if [ "$ANS" = "1" ]
@@ -112,10 +114,24 @@
         LDFLAG="$GST_LIBS -L/usr/X11R6/lib -L/usr/local/lib"
         ARFLAG="rs"
         RANLIB=""
-        LIBS="-lpthread -lglut -lGLU -lGL -lXi -lX11 -lm"
+        LIBS="-lpthread -lglut -lGLU -lGL -lXi -lX11 -lm $GST_LIBS"
         CONFIG="AR_INPUT_GSTREAMER"
+    elif [ "$ANS" = "6" ]
+    then
+        VIDEO_DRIVER="VideoOpenKinect"
+		GST_INCLUDE=`pkg-config --cflags gstreamer-0.10`
+		GST_LIBS=`pkg-config --libs gstreamer-0.10`
+        	FREENECT_INCLUDE=`pkg-config --cflags libfreenect`
+        	FREENECT_LIBS=`pkg-config --libs libfreenect`
+		
+		CFLAG="-O $GST_INCLUDE $FREENECT_INCLUDE -I/usr/X11R6/include"
+        LDFLAG="$GST_LIBS $FREENECT_LIBS -L/usr/X11R6/lib -L/usr/local/lib"
+        ARFLAG="rs"
+        RANLIB=""
+        LIBS="-lpthread -lglut -lGLU -lGL -lXi -lX11 -lm -lusb-1.0 -lfreenect"
+        CONFIG="AR_INPUT_OPENKINECT"
     else
-        echo "Please enter 1,2,3,4 or 5."
+        echo "Please enter 1,2,3,4,5 or 6."
         exit 0
     fi
 	# Asking for debug mode (assumes gcc)
diff -Naur ARToolKit/examples/Makefile.in ARToolKit-Freenect/examples/Makefile.in
--- ARToolKit/examples/Makefile.in	2004-12-01 05:54:41.000000000 +0100
+++ ARToolKit-Freenect/examples/Makefile.in	2012-06-13 02:13:51.726618839 +0200
@@ -14,6 +14,7 @@
 	(cd optical;           make -f Makefile)		
 	(cd modeTest;          make -f Makefile)
 	(cd exview;            make -f Makefile)
+	(cd openKinect;        make -f Makefile)
 	
 clean:
 	(cd simple;            make -f Makefile clean)
@@ -32,6 +33,7 @@
 	(cd modeTest;          make -f Makefile clean)
 	(cd exview;            make -f Makefile clean)
 	(cd simpleVRML;        make -f Makefile clean)
+	(cd openKinect;        make -f Makefile clean)
 
 allclean:
 	(cd simple;            make -f Makefile allclean)
@@ -50,4 +52,5 @@
 	(cd modeTest;          make -f Makefile allclean)
 	(cd exview;            make -f Makefile allclean)
 	(cd simpleVRML;        make -f Makefile allclean)
+	(cd openKinect;        make -f Makefile allclean)
 	rm -f Makefile
diff -Naur ARToolKit/examples/openKinect/Makefile ARToolKit-Freenect/examples/openKinect/Makefile
--- ARToolKit/examples/openKinect/Makefile	1970-01-01 01:00:00.000000000 +0100
+++ ARToolKit-Freenect/examples/openKinect/Makefile	2012-06-13 02:13:51.726618839 +0200
@@ -0,0 +1,33 @@
+INC_DIR= ../../include
+LIB_DIR= ../../lib
+BIN_DIR= ../../bin
+
+FREENECT_INCLUDE=`pkg-config --cflags libfreenect`
+FREENECT_LIBS=`pkg-config --libs libfreenect`
+
+LDFLAG=-pthread -lgstreamer-0.10 -lgobject-2.0 -lgmodule-2.0 -lxml2 -lgthread-2.0 -lrt -lglib-2.0 $FREENECT_LIBS -L/usr/X11R6/lib -L/usr/local/lib -L$(LIB_DIR)
+LIBS= -lARgsub -lARvideo -lAR -lpthread -lglut -lGLU -lGL -lXi -lX11 -lm -lusb-1.0 -lfreenect
+CFLAG= -O -pthread -I/usr/include/gstreamer-0.10 -I/usr/include/glib-2.0 -I/usr/lib/glib-2.0/include -I/usr/include/libxml2 $FREENECT_INCLUDE -I/usr/X11R6/include -g -I$(INC_DIR)
+
+OBJS =
+HEADDERS = pointcloud.h
+
+all: $(BIN_DIR)/openKinect
+
+$(BIN_DIR)/openKinect: openkinect.o pointcloud.o $(OBJS)
+	cc -o $(BIN_DIR)/openkinect openkinect.o pointcloud.o $(OBJS) $(LDFLAG) $(LIBS)
+
+openkinect.o: openkinect.c $(HEADDERS)
+	cc -c $(CFLAG) openkinect.c
+
+pointcloud.o: pointcloud.c $(HEADDERS)
+	cc -c $(CFLAG) pointcloud.c
+
+clean:
+	rm -f *.o
+	rm -f $(BIN_DIR)/openKinect
+
+allclean:
+	rm -f *.o
+	rm -f $(BIN_DIR)/openKinect
+	rm -f Makefile
diff -Naur ARToolKit/examples/openKinect/Makefile.in ARToolKit-Freenect/examples/openKinect/Makefile.in
--- ARToolKit/examples/openKinect/Makefile.in	1970-01-01 01:00:00.000000000 +0100
+++ ARToolKit-Freenect/examples/openKinect/Makefile.in	2012-06-13 02:13:51.726618839 +0200
@@ -0,0 +1,30 @@
+INC_DIR= ../../include
+LIB_DIR= ../../lib
+BIN_DIR= ../../bin
+
+LDFLAG=@LDFLAG@ -L$(LIB_DIR)
+LIBS= -lARgsub -lARvideo -lAR @LIBS@
+CFLAG= @CFLAG@ -I$(INC_DIR)
+
+OBJS =
+HEADDERS = pointcloud.h
+
+all: $(BIN_DIR)/openKinect
+
+$(BIN_DIR)/openKinect: openkinect.o pointcloud.o $(OBJS)
+	cc -o $(BIN_DIR)/openkinect openkinect.o pointcloud.o $(OBJS) $(LDFLAG) $(LIBS)
+
+openkinect.o: openkinect.c $(HEADDERS)
+	cc -c $(CFLAG) openkinect.c
+
+pointcloud.o: pointcloud.c $(HEADDERS)
+	cc -c $(CFLAG) pointcloud.c
+
+clean:
+	rm -f *.o
+	rm -f $(BIN_DIR)/openKinect
+
+allclean:
+	rm -f *.o
+	rm -f $(BIN_DIR)/openKinect
+	rm -f Makefile
diff -Naur ARToolKit/examples/openKinect/openkinect.c ARToolKit-Freenect/examples/openKinect/openkinect.c
--- ARToolKit/examples/openKinect/openkinect.c	1970-01-01 01:00:00.000000000 +0100
+++ ARToolKit-Freenect/examples/openKinect/openkinect.c	2012-06-13 02:13:51.726618839 +0200
@@ -0,0 +1,233 @@
+#ifdef _WIN32
+#include <windows.h>
+#endif
+#include <stdio.h>
+#include <stdlib.h>
+#ifndef __APPLE__
+#include <GL/gl.h>
+#include <GL/glut.h>
+#else
+#include <OpenGL/gl.h>
+#include <GLUT/glut.h>
+#endif
+#include <AR/gsub.h>
+#include <AR/video.h>
+#include <AR/param.h>
+#include <AR/ar.h>
+
+#include "pointcloud.h"
+
+/* set up the video format globals */
+
+#ifdef _WIN32
+char			*vconf = "Data\\WDM_camera_flipV.xml";
+#else
+char			*vconf = "";
+#endif
+
+int             xsize, ysize;
+int             thresh = 100;
+int             count = 0;
+
+int             mode = 1;
+
+char           *cparam_name    = "Data/camera_para.dat";
+ARParam         cparam;
+
+char           *patt_name      = "Data/patt.hiro";
+int             patt_id;
+int             patt_width     = 80.0;
+double          patt_center[2] = {0.0, 0.0};
+double          patt_trans[3][4];
+
+
+static void   init(void);
+static void   cleanup(void);
+static void   keyEvent( unsigned char key, int x, int y);
+static void   mainLoop(void);
+static void   draw( double trans[3][4] );
+
+int main(int argc, char **argv)
+{
+	glutInit(&argc, argv);
+    init();
+
+    arVideoCapStart();
+    argMainLoop( NULL, keyEvent, mainLoop );
+	return (0);
+}
+
+static void   keyEvent( unsigned char key, int x, int y)
+{
+    /* quit if the ESC key is pressed */
+    if( key == 0x1b ) {
+        printf("*** %f (frame/sec)\n", (double)count/arUtilTimer());
+        cleanup();
+        exit(0);
+    }
+
+    if( key == 'c' ) {
+        printf("*** %f (frame/sec)\n", (double)count/arUtilTimer());
+        count = 0;
+
+        mode = 1 - mode;
+        if( mode ) printf("Continuous mode: Using arGetTransMatCont.\n");
+         else      printf("One shot mode: Using arGetTransMat.\n");
+    }
+}
+
+/* main loop */
+static void mainLoop(void)
+{
+    static int      contF = 0;
+    ARUint8         *dataPtr = NULL;
+    ARUint32        *depthBuffer = NULL;
+    ARMarkerInfo    *marker_info;
+    int             marker_num;
+    int             j, k;
+
+    /* grab a vide frame */
+    if( (dataPtr = (ARUint8 *)arVideoGetImage()) == NULL ) {
+        arUtilSleep(2);
+        return;
+    }
+    if( count == 0 ) arUtilTimerReset();
+    count++;
+
+    argDrawMode2D();
+    argDispImage( dataPtr, 0,0 );
+
+    /* compute point cloud */
+    depthBuffer = arVideoGetDepthImage();
+    setPointCloud(dataPtr, depthBuffer);
+
+
+    /* detect the markers in the video frame */
+    if( arDetectMarker(dataPtr, thresh, &marker_info, &marker_num) < 0 ) {
+        cleanup();
+        exit(0);
+    }
+
+    arVideoCapNext();
+
+    /* check for object visibility */
+    k = -1;
+    for( j = 0; j < marker_num; j++ ) {
+        if( patt_id == marker_info[j].id ) {
+            if( k == -1 ) k = j;
+            else if( marker_info[k].cf < marker_info[j].cf ) k = j;
+        }
+    }
+    if( k == -1 ) {
+        contF = 0;
+        argSwapBuffers();
+        return;
+    }
+
+    /* get the transformation between the marker and the real camera */
+    if( mode == 0 || contF == 0 ) {
+        arGetTransMat(&marker_info[k], patt_center, patt_width, patt_trans);
+    }
+    else {
+        arGetTransMatCont(&marker_info[k], patt_trans, patt_center, patt_width, patt_trans);
+    }
+    contF = 1;
+
+    draw( patt_trans );
+
+    argSwapBuffers();
+}
+
+static void init( void )
+{
+    ARParam  wparam;
+
+    /* open the video path */
+    if( arVideoOpen( vconf ) < 0 ) exit(0);
+    /* find the size of the window */
+    if( arVideoInqSize(&xsize, &ysize) < 0 ) exit(0);
+    printf("Image size (x,y) = (%d,%d)\n", xsize, ysize);
+
+    /* set the initial camera parameters */
+    if( arParamLoad(cparam_name, 1, &wparam) < 0 ) {
+        printf("Camera parameter load error !!\n");
+        exit(0);
+    }
+    arParamChangeSize( &wparam, xsize, ysize, &cparam );
+    arInitCparam( &cparam );
+    printf("*** Camera Parameter ***\n");
+    arParamDisp( &cparam );
+
+    if( (patt_id=arLoadPatt(patt_name)) < 0 ) {
+        printf("pattern load error !!\n");
+        exit(0);
+    }
+
+    /* init point cloud rendering */
+    initPointCloud(640, 480);
+
+    /* open the graphics window */
+    argInit( &cparam, 1.0, 0, 0, 0, 0 );
+}
+
+/* cleanup function called when program exits */
+static void cleanup(void)
+{
+    arVideoCapStop();
+    arVideoClose();
+    argCleanup();
+}
+
+static void draw( double trans[3][4] )
+{
+    double    gl_para[16];
+    GLfloat   mat_ambient[]     = {0.0, 0.0, 1.0, 1.0};
+    GLfloat   mat_flash[]       = {0.0, 0.0, 1.0, 1.0};
+    GLfloat   mat_flash_shiny[] = {50.0};
+    GLfloat   light_position[]  = {100.0,-200.0,200.0,0.0};
+    GLfloat   ambi[]            = {0.1, 0.1, 0.1, 0.1};
+    GLfloat   lightZeroColor[]  = {0.9, 0.9, 0.9, 0.1};
+    
+    argDrawMode3D();
+    argDraw3dCamera( 0, 0 );
+    glClearDepth( 1.0 );
+    glClear(GL_DEPTH_BUFFER_BIT);
+    glEnable(GL_DEPTH_TEST);
+    glDepthFunc(GL_LEQUAL);
+
+    
+    /* load the camera transformation matrix */
+    argConvGlpara(trans, gl_para);
+    glMatrixMode(GL_MODELVIEW);
+    glLoadMatrixd( gl_para );
+
+    glEnable(GL_LIGHTING);
+    glEnable(GL_LIGHT0);
+    glLightfv(GL_LIGHT0, GL_POSITION, light_position);
+    glLightfv(GL_LIGHT0, GL_AMBIENT, ambi);
+    glLightfv(GL_LIGHT0, GL_DIFFUSE, lightZeroColor);
+    glMaterialfv(GL_FRONT, GL_SPECULAR, mat_flash);
+    glMaterialfv(GL_FRONT, GL_SHININESS, mat_flash_shiny);	
+    glMaterialfv(GL_FRONT, GL_AMBIENT, mat_ambient);
+    glMatrixMode(GL_MODELVIEW);
+    glScalef( 1.0, 1.0, 3.0 );
+    glTranslatef( 0.0, 0.0, 25.0 );
+    glutSolidCube(50.0);
+
+    glLoadIdentity();
+    glDisable( GL_LIGHTING );
+    glTranslatef( 0.0, 0.0, 400.0 );
+    glColor3f(1.0, 0.0, 0.0);
+    glBegin(GL_POINTS);
+        glVertex3f(-30.0, 0.0, 0.0);
+    glEnd();
+    
+    renderPointCloud();
+    //glutSolidCube(50.0);
+
+
+    glDisable( GL_DEPTH_TEST );
+}
+
+
+
diff -Naur ARToolKit/examples/openKinect/pointcloud.c ARToolKit-Freenect/examples/openKinect/pointcloud.c
--- ARToolKit/examples/openKinect/pointcloud.c	1970-01-01 01:00:00.000000000 +0100
+++ ARToolKit-Freenect/examples/openKinect/pointcloud.c	2012-06-13 02:13:51.726618839 +0200
@@ -0,0 +1,160 @@
+#include "pointcloud.h"
+
+#include <stdlib.h>
+
+#include <GL/gl.h>
+#include <GL/glut.h>
+
+
+static PointCloudDataT *gPCD = 0;
+
+/* converts the 11-bit integer from depth sensor to mm */
+float raw_depth_to_meter(ARUint32 rd) {
+    //printf("rd: %i\n", rd);
+    if (rd < 2047 && rd > 0) {
+        return (1.0 / (rd * -0.0030711016 + 3.3309495161));
+    }
+    return 0;
+}
+
+
+void sample_color(float* color, ARUint8* rgbBuffer, float x, float y) {
+    /* just nearest neighbor for now */
+    //printf("sample %i,%i\n", x, y);
+    ARUint8 *tc = &rgbBuffer[(int)x + gPCD->width*(int)y];
+    color[0] = tc[0] / 255;
+    color[1] = tc[1] / 255;
+    color[2] = tc[2] / 255;
+}
+
+
+/*********************************************************/
+
+void initPointCloud(int width, int height) {
+    int max_points = width*height;
+
+    gPCD = malloc(sizeof(PointCloudDataT));
+    
+    gPCD->width = width;
+    gPCD->height = height;
+
+    /* allocating buffers */
+    gPCD->points = malloc(sizeof(float) * max_points * 3);
+    gPCD->colors = malloc(sizeof(float) * max_points * 3);
+    gPCD->max_points = max_points;
+
+    gPCD->valid_points = 0;
+}
+
+
+void setPointCloud(ARUint8* rgbBuffer, int* depthBuffer) {
+    float *pointP, *colorP;
+    int *depthP = depthBuffer;
+    float depthM;
+
+    /***** Calibration Data Start *******/
+    float R[9] = { 9.9984628826577793e-01, 1.2635359098409581e-03,
+                  -1.7487233004436643e-02,-1.4779096108364480e-03,
+                   9.9992385683542895e-01,-1.2251380107679535e-02,
+                   1.7470421412464927e-02, 1.2275341476520762e-02,
+                   9.9977202419716948e-01 };
+
+    float T[3] = { 1.9985242312092553e-02, -7.4423738761617583e-04, -1.0916736334336222e-02 };
+   
+    /* rgb camera */ 
+    float fx_rgb = 5.2921508098293293e+02;
+    float fy_rgb = 5.2556393630057437e+02;
+    float cx_rgb = 3.2894272028759258e+02;
+    float cy_rgb = 2.6748068171871557e+02;
+
+    /* ir camera */
+    float fx_d = 5.9421434211923247e+02;
+    float fy_d = 5.9104053696870778e+02;
+    float cx_d = 3.3930780975300314e+02;
+    float cy_d = 2.4273913761751615e+02;
+    /***** Calibration Data End  ********/
+
+    // ir camera space
+    float p3dX, p3dY, p3dZ;
+    // rgb camera space
+    float p3dX_c, p3dY_c, p3dZ_c;
+    float p2dX_c, p2dY_c;
+    // pixel
+    int x_d, y_d;
+
+    if (gPCD == NULL || depthBuffer == NULL || rgbBuffer == NULL) {
+       return;
+    } 
+
+    pointP = gPCD->points;
+    colorP = gPCD->colors;
+
+    gPCD->valid_points = 0;
+
+    for (x_d=0; x_d<gPCD->width; x_d++) {
+        for (y_d=0; y_d<gPCD->height; y_d++) {
+
+            depthM = raw_depth_to_meter(*depthP);
+            //printf("depthM: %f\n", depthM);
+            depthP++;
+            if (depthM == 0.0f) {
+                continue;
+            }
+
+            /* transform the depth pixel into 3d space of the depth camera */
+            p3dX = (x_d - cx_d) * depthM/fx_d;
+            p3dY = (y_d - cy_d) * depthM/fy_d;
+            p3dZ = depthM;
+
+            /* transform the point to rgb camera space */
+            p3dX_c = (R[0]*p3dX + R[1]*p3dY + R[2]*p3dZ) + T[0];
+            p3dY_c = (R[3]*p3dX + R[4]*p3dY + R[5]*p3dZ) + T[1];
+            p3dZ_c = (R[6]*p3dX + R[7]*p3dY + R[8]*p3dZ) + T[2];
+
+            /* project on camera rgb image */
+            //P2D_rgb.x = (P3D'.x * fx_rgb / P3D'.z) + cx_rgb
+            //P2D_rgb.y = (P3D'.y * fy_rgb / P3D'.z) + cy_rgb 
+            p2dX_c = (p3dX_c*fx_rgb) / p3dZ_c + cx_rgb;
+            p2dY_c = (p3dY_c*fy_rgb) / p3dZ_c + cy_rgb;
+
+            /* sample color from the rgb camera */
+            printf("rgb projection [%f,%f]\n", p2dX_c, p2dY_c);
+            sample_color(colorP, rgbBuffer, p2dX_c, p2dY_c);
+            //printf("color[%f,%f,%f]\n", colorP[0], colorP[1], colorP[2]);
+            colorP += 3;
+           
+            /* set coordinates of the point */
+            pointP[0] = p3dX_c;
+            pointP[1] = p3dY_c;
+            pointP[2] = p3dZ_c;
+            //pointP[0] = p3dX;
+            //pointP[1] = p3dY;
+            //pointP[2] = p3dZ;
+            pointP += 3;
+
+            gPCD->valid_points++;
+        }
+    }
+   
+}
+
+
+void renderPointCloud() {
+    int i;
+    glLoadIdentity();
+    glDisable( GL_LIGHTING );
+    for (i=0; i<(gPCD->valid_points*3); i+=3) {
+        glColor3f(gPCD->colors[i], gPCD->colors[i+1], gPCD->colors[i+2]);
+        //printf("color[%f,%f,%f]\n", gPCD->colors[i], gPCD->colors[i+1], gPCD->colors[i+2]);
+        //printf("point[%f,%f,%f]\n", gPCD->points[i], gPCD->points[i+1], gPCD->points[i+2]);
+        glBegin(GL_POINTS);
+            //to mm
+            glVertex3f(gPCD->points[i]*1000, gPCD->points[i+1]*1000, gPCD->points[i+2]*1000);
+            //glVertex3f(gPCD->points[i], gPCD->points[i+1], gPCD->points[i+2]);
+        glEnd();
+    }
+}
+
+
+
+
diff -Naur ARToolKit/examples/openKinect/pointcloud.h ARToolKit-Freenect/examples/openKinect/pointcloud.h
--- ARToolKit/examples/openKinect/pointcloud.h	1970-01-01 01:00:00.000000000 +0100
+++ ARToolKit-Freenect/examples/openKinect/pointcloud.h	2012-06-13 02:13:51.726618839 +0200
@@ -0,0 +1,19 @@
+
+/* include AR Toolkit*/
+#include <AR/config.h>
+#include <AR/ar.h>
+#include <AR/video.h>
+
+typedef struct PointCloudDataT {
+    float *points;
+    float *colors;
+    int max_points;
+    int valid_points;
+
+    int width;
+    int height;
+} PointCloudDataT;
+
+void initPointCloud(int width, int height);
+void setPointCloud(ARUint8* rgbBuffer, int* depthBuffer);
+void renderPointCloud();
diff -Naur ARToolKit/include/AR/config.h.in ARToolKit-Freenect/include/AR/config.h.in
--- ARToolKit/include/AR/config.h.in	2006-11-19 22:21:11.000000000 +0100
+++ ARToolKit-Freenect/include/AR/config.h.in	2012-06-13 02:13:51.726618839 +0200
@@ -73,6 +73,7 @@
 #undef  AR_INPUT_DV
 #undef  AR_INPUT_1394CAM
 #undef  AR_INPUT_GSTREAMER
+#undef  AR_INPUT_OPENKINECT
 
 #  ifdef AR_INPUT_V4L
 #    ifdef USE_EYETOY
@@ -94,6 +95,10 @@
 #    define  AR_DEFAULT_PIXEL_FORMAT AR_PIXEL_FORMAT_RGB
 #  endif
 
+#  ifdef AR_INPUT_OPENKINECT
+#    define  AR_DEFAULT_PIXEL_FORMAT AR_PIXEL_FORMAT_RGB
+#  endif
+
 #  undef   AR_BIG_ENDIAN
 #  define  AR_LITTLE_ENDIAN
 #endif
diff -Naur ARToolKit/include/AR/sys/videoOpenKinect.h ARToolKit-Freenect/include/AR/sys/videoOpenKinect.h
--- ARToolKit/include/AR/sys/videoOpenKinect.h	1970-01-01 01:00:00.000000000 +0100
+++ ARToolKit-Freenect/include/AR/sys/videoOpenKinect.h	2012-06-13 02:13:51.726618839 +0200
@@ -0,0 +1,34 @@
+/*
+ * Video capture module with OpenKinect for ARToolkit
+ * 
+ * (c) Copyrights 2010 Aurel Wildfellner
+ * 
+ * Licensed under the terms of the GPL
+ *
+ */
+#ifndef AR_VIDEO_OPENKINECT_H
+#define AR_VIDEO_OPENKINECT_H
+
+#ifdef  __cplusplus
+extern "C" {
+#endif
+
+#include <AR/config.h>
+#include <AR/ar.h>
+
+typedef struct _AR2VideoParamT AR2VideoParamT;
+
+#ifdef  __cplusplus
+}
+#endif
+
+/* extended API for depth access */
+AR_DLL_API  int             arVideoInqDepthSize(int *x, int *y);
+AR_DLL_API  int             ar2VideoInqDepthSize(AR2VideoParamT *vid, int *x, int *y);
+
+AR_DLL_API  ARUint32*            arVideoGetDepthImage(void);
+AR_DLL_API  ARUint32*            ar2VideoGetDepthImage(AR2VideoParamT *vid);
+
+
+#endif
+
diff -Naur ARToolKit/include/AR/video.h ARToolKit-Freenect/include/AR/video.h
--- ARToolKit/include/AR/video.h	2007-01-23 01:39:27.000000000 +0100
+++ ARToolKit-Freenect/include/AR/video.h	2012-06-13 02:13:51.726618839 +0200
@@ -110,6 +110,9 @@
 #  ifdef  AR_INPUT_GSTREAMER
 #    include <AR/sys/videoGStreamer.h>
 #  endif
+#  ifdef  AR_INPUT_OPENKINECT
+#    include <AR/sys/videoOpenKinect.h>
+#  endif
 #endif
 
 #ifdef __sgi
diff -Naur ARToolKit/lib/SRC/Makefile.in ARToolKit-Freenect/lib/SRC/Makefile.in
--- ARToolKit/lib/SRC/Makefile.in	2006-07-10 06:35:17.000000000 +0200
+++ ARToolKit-Freenect/lib/SRC/Makefile.in	2012-06-13 02:13:51.730618719 +0200
@@ -17,6 +17,7 @@
 	(cd VideoMacOSX;       make -f Makefile clean)
 	(cd ARvrml;     make -f Makefile clean)
 	(cd VideoGStreamer;    make -f Makefile clean)
+	(cd VideoOpenKinect;   make -f Makefile clean)
 
 allclean:
 	(cd AR;         make -f Makefile allclean)
@@ -29,4 +30,5 @@
 	(cd VideoMacOSX;       make -f Makefile allclean)
 	(cd ARvrml;     make -f Makefile allclean)
 	(cd VideoGStreamer;    make -f Makefile allclean)
+	(cd VideoOpenKinect;   make -f Makefile allclean)
 	rm -f Makefile
diff -Naur ARToolKit/lib/SRC/VideoOpenKinect/Makefile.in ARToolKit-Freenect/lib/SRC/VideoOpenKinect/Makefile.in
--- ARToolKit/lib/SRC/VideoOpenKinect/Makefile.in	1970-01-01 01:00:00.000000000 +0100
+++ ARToolKit-Freenect/lib/SRC/VideoOpenKinect/Makefile.in	2012-06-13 02:13:51.730618719 +0200
@@ -0,0 +1,42 @@
+#
+# For instalation. Change this to your settings.
+#
+INC_DIR = ../../../include
+LIB_DIR = ../..
+#
+#  compiler
+#
+CC=cc
+CFLAG= @CFLAG@ -I$(INC_DIR)
+#
+# For making the library
+#
+AR= ar
+ARFLAGS= @ARFLAG@
+#
+#   products
+#
+LIB= ${LIB_DIR}/libARvideo.a
+INCLUDE= ${INC_DIR}/AR/video.h
+#
+#   compilation control
+#
+LIBOBJS= ${LIB}(video.o)
+
+all:		${LIBOBJS}
+
+${LIBOBJS}:	${INCLUDE}
+
+.c.a:
+	${CC} -c ${CFLAG} $<
+	${AR} ${ARFLAGS} $@ $*.o
+	rm -f $*.o
+
+clean:
+	rm -f *.o
+	rm -f ${LIB}
+
+allclean:
+	rm -f *.o
+	rm -f ${LIB}
+	rm -f Makefile
diff -Naur ARToolKit/lib/SRC/VideoOpenKinect/video.c ARToolKit-Freenect/lib/SRC/VideoOpenKinect/video.c
--- ARToolKit/lib/SRC/VideoOpenKinect/video.c	1970-01-01 01:00:00.000000000 +0100
+++ ARToolKit-Freenect/lib/SRC/VideoOpenKinect/video.c	2012-06-13 02:13:51.730618719 +0200
@@ -0,0 +1,261 @@
+/*
+ * Video capture module with libfreenect for AR Toolkit
+ * 
+ * (c) Copyrights 2010 Aurel Wildfellner
+ * 
+ * licensed under the terms of the GPL v2.0
+ *
+ */
+
+/* include AR Toolkit*/ 
+#include <AR/config.h>
+#include <AR/ar.h>
+#include <AR/video.h>
+
+/* include GLib for GStreamer */
+#include <glib.h>
+
+/* using memcpy */
+#include <string.h>
+#include <pthread.h>
+
+#include <libfreenect.h>
+
+
+struct _AR2VideoParamT {
+	/* size of the image */
+	int	width, height;
+
+	/* the actual video buffer 
+       double buffering is done in render part,
+        so simply lock and copy here */
+    ARUint8             *backBuffer;
+    ARUint8             *frontBuffer;
+    size_t              rgbBuffer_size;
+
+    int depthWidth, depthHeight;
+    ARUint32 *depthBuffer;
+    size_t depthBuffer_size;
+
+    /* freenect */
+    freenect_context *f_ctx;
+    freenect_device *f_dev;
+
+    pthread_mutex_t videoBuffer_mutex;
+    pthread_t freenect_event_thread;
+
+    int streaming;
+};
+
+
+static AR2VideoParamT* gVid = 0;
+
+
+int arVideoOpen( char *config ) {
+   if( gVid != NULL ) {
+        printf("Device has been opened!!\n");
+        return -1;
+    }
+    gVid = ar2VideoOpen( config );
+    if( gVid == NULL ) return -1;
+}
+
+int arVideoClose( void ) {
+	return ar2VideoClose(gVid);
+}
+
+int arVideoDispOption( void ) {
+   return 0;
+}
+
+int arVideoInqSize( int *x, int *y ) {
+	ar2VideoInqSize(gVid,x,y);
+	return 0;
+}
+
+ARUint8 *arVideoGetImage( void ) {
+   return ar2VideoGetImage(gVid);  // address of your image data
+}
+
+int arVideoCapStart( void ) {
+	ar2VideoCapStart(gVid);
+	return 0;
+}
+
+int arVideoCapStop( void ) {
+	ar2VideoCapStop(gVid);
+	return 0;
+}
+
+int arVideoCapNext( void ) {
+	ar2VideoCapNext(gVid);
+	return 0;
+}
+
+int arVideoInqDepthSize(int *x, int *y) {
+    ar2VideoInqDepthSize(gVid, x, y);
+    return 0;
+}
+
+ARUint32* arVideoGetDepthImage() {
+    return gVid->depthBuffer;
+}
+
+/*---------------------------------------------------------------------------*/
+
+
+void *freenect_threadfunc(void *arg) {
+    while (freenect_process_events(gVid->f_ctx) >= 0 && gVid->streaming);
+    pthread_exit(NULL);
+}
+
+
+void rgb_cb(freenect_device *dev, uint8_t *rgb, uint32_t timestamp) {
+    ARUint8 *hbuf;    
+    if (!gVid->backBuffer) return;
+
+    pthread_mutex_lock(&gVid->videoBuffer_mutex);
+
+    memcpy(gVid->backBuffer, rgb, gVid->rgbBuffer_size);
+    hbuf = gVid->backBuffer;
+    gVid->backBuffer = gVid->frontBuffer;
+    gVid->frontBuffer = hbuf;
+
+    pthread_mutex_unlock(&gVid->videoBuffer_mutex);
+}
+
+
+void depth_cb(freenect_device *dev, uint16_t *depth, uint32_t timestamp) {
+    int i;
+
+    for (i=0; i<gVid->depthWidth*gVid->depthHeight; i++) {
+        gVid->depthBuffer[i] = depth[i];
+    }
+}
+
+
+AR2VideoParamT* ar2VideoOpen(char *config_in ) {
+
+	AR2VideoParamT *vid = 0;
+	GError *error = 0;
+	char *config;
+
+	/* If no config string is supplied, we should use the environment variable, otherwise set a sane default */
+	if (!config_in || !(config_in[0])) {
+		/* None suppplied, lets see if the user supplied one from the shell */
+		char *envconf = getenv ("ARTOOLKIT_CONFIG");
+		if (envconf && envconf[0]) {
+			config = envconf;
+			g_printf ("Using config string from environment [%s].\n", envconf);
+		} else {
+			config = NULL;
+			g_printf ("No video config string supplied, using defaults.\n");
+		}
+	} else {
+		config = config_in;
+		g_printf ("Using supplied video config string [%s].\n", config_in);
+	}
+
+    /* init ART structure */
+    arMalloc( vid, AR2VideoParamT, 1 );
+
+    /* allocate the buffer */
+
+    vid->width = 640;
+    vid->height = 480;
+    vid->rgbBuffer_size = vid->width * vid->height * 3 * sizeof(ARUint8);
+    vid->backBuffer = (ARUint8*) malloc(vid->rgbBuffer_size);
+    vid->frontBuffer = (ARUint8*) malloc(vid->rgbBuffer_size);
+
+    vid->depthWidth = 640;
+    vid->depthHeight = 480;
+    vid->depthBuffer_size = vid->width * vid->height * sizeof(ARUint32);
+    vid->depthBuffer = (ARUint32*) malloc(vid->depthBuffer_size);
+
+    vid->streaming = FALSE;
+		
+    /* report the current version and features */
+    g_print ("libARvideo: libfreenect-0.0.1 init\n");
+
+    /* libfreenect init */
+    if (freenect_init(&(vid->f_ctx), NULL) < 0) {
+        g_error ("libARVideo: freenect_init() FAILED!\n");
+        printf("fail-init\n");
+    }
+
+    if (freenect_open_device(vid->f_ctx, &(vid->f_dev), 0) < 0) {
+        g_error("libARVideo: opening a kinect device FAILED!\n");
+        printf("fail-open\n");
+    }
+
+    //freenect_set_tilt_degs(vid->f_dev, 0);
+    freenect_set_led(vid->f_dev, LED_RED);
+    freenect_set_depth_callback(vid->f_dev, depth_cb);
+    freenect_set_video_callback(vid->f_dev, rgb_cb);
+    freenect_set_video_format(vid->f_dev, FREENECT_VIDEO_RGB);
+    freenect_set_depth_format(vid->f_dev, FREENECT_DEPTH_11BIT);
+
+    pthread_mutex_init(&vid->videoBuffer_mutex, NULL);
+	
+    /* return the video handle */
+    gVid = vid;
+    return vid;
+}
+
+
+int ar2VideoClose(AR2VideoParamT *vid) {
+    freenect_set_led(vid->f_dev, LED_GREEN);
+    vid->streaming = FALSE;    
+	return 0;
+}
+
+
+ARUint8* ar2VideoGetImage(AR2VideoParamT *vid) {
+    ARUint8 *tb;
+	/* just return the bare video buffer */   
+    pthread_mutex_lock(&vid->videoBuffer_mutex);
+    tb = vid->frontBuffer;
+    pthread_mutex_unlock(&vid->videoBuffer_mutex);
+	return tb;
+}
+
+
+int ar2VideoCapStart(AR2VideoParamT *vid) {
+    vid->streaming = TRUE;
+    if ( pthread_create(&(vid->freenect_event_thread), NULL, freenect_threadfunc, NULL) ) {
+        g_error("libARVideo: creating thread FAILED!\n");
+    }
+    freenect_start_video(vid->f_dev);
+    freenect_start_depth(vid->f_dev);
+
+    return 0;
+}
+
+
+int ar2VideoCapStop(AR2VideoParamT *vid) {
+	/* stop pipeline */
+	g_error("libARVideo: can't stop streaming");
+}
+
+
+int ar2VideoCapNext(AR2VideoParamT *vid) {
+	/* gstreamer should */
+	return TRUE;
+}
+
+
+int ar2VideoInqSize(AR2VideoParamT *vid, int *x, int *y ) {
+   *x = vid->width; // width of your static image
+   *y = vid->height; // height of your static image
+}
+
+
+int ar2VideoInqDepthSize(AR2VideoParamT *vid, int *x, int *y ) {
+    *x = vid->depthWidth;
+    *y = vid->depthHeight;
+}
+
+ARUint32 *ar2VideoGetDepthImage(AR2VideoParamT* vid) {
+    return vid->depthBuffer;
+}
+
diff -Naur ARToolKit/lib/SRC/VideoOpenKinect/video.c.bak ARToolKit-Freenect/lib/SRC/VideoOpenKinect/video.c.bak
--- ARToolKit/lib/SRC/VideoOpenKinect/video.c.bak	1970-01-01 01:00:00.000000000 +0100
+++ ARToolKit-Freenect/lib/SRC/VideoOpenKinect/video.c.bak	2012-06-13 02:13:51.730618719 +0200
@@ -0,0 +1,261 @@
+/*
+ * Video capture module with libfreenect for AR Toolkit
+ * 
+ * (c) Copyrights 2010 Aurel Wildfellner
+ * 
+ * licensed under the terms of the GPL v2.0
+ *
+ */
+
+/* include AR Toolkit*/ 
+#include <AR/config.h>
+#include <AR/ar.h>
+#include <AR/video.h>
+
+/* include GLib for GStreamer */
+#include <glib.h>
+
+/* using memcpy */
+#include <string.h>
+#include <pthread.h>
+
+#include <libfreenect.h>
+
+
+struct _AR2VideoParamT {
+	/* size of the image */
+	int	width, height;
+
+	/* the actual video buffer 
+       double buffering is done in render part,
+        so simply lock and copy here */
+    ARUint8             *backBuffer;
+    ARUint8             *frontBuffer;
+    size_t              rgbBuffer_size;
+
+    int depthWidth, depthHeight;
+    ARUint32 *depthBuffer;
+    size_t depthBuffer_size;
+
+    /* freenect */
+    freenect_context *f_ctx;
+    freenect_device *f_dev;
+
+    pthread_mutex_t videoBuffer_mutex;
+    pthread_t freenect_event_thread;
+
+    int streaming;
+};
+
+
+static AR2VideoParamT* gVid = 0;
+
+
+int arVideoOpen( char *config ) {
+   if( gVid != NULL ) {
+        printf("Device has been opened!!\n");
+        return -1;
+    }
+    gVid = ar2VideoOpen( config );
+    if( gVid == NULL ) return -1;
+}
+
+int arVideoClose( void ) {
+	return ar2VideoClose(gVid);
+}
+
+int arVideoDispOption( void ) {
+   return 0;
+}
+
+int arVideoInqSize( int *x, int *y ) {
+	ar2VideoInqSize(gVid,x,y);
+	return 0;
+}
+
+ARUint8 *arVideoGetImage( void ) {
+   return ar2VideoGetImage(gVid);  // address of your image data
+}
+
+int arVideoCapStart( void ) {
+	ar2VideoCapStart(gVid);
+	return 0;
+}
+
+int arVideoCapStop( void ) {
+	ar2VideoCapStop(gVid);
+	return 0;
+}
+
+int arVideoCapNext( void ) {
+	ar2VideoCapNext(gVid);
+	return 0;
+}
+
+int arVideoInqDepthSize(int *x, int *y) {
+    ar2VideoInqDepthSize(gVid, x, y);
+    return 0;
+}
+
+ARUint32* arVideoGetDepthImage() {
+    return gVid->depthBuffer;
+}
+
+/*---------------------------------------------------------------------------*/
+
+
+void *freenect_threadfunc(void *arg) {
+    while (freenect_process_events(gVid->f_ctx) >= 0 && gVid->streaming);
+    pthread_exit(NULL);
+}
+
+
+void rgb_cb(freenect_device *dev, freenect_pixel *rgb, uint32_t timestamp) {
+    ARUint8 *hbuf;    
+    if (!gVid->backBuffer) return;
+
+    pthread_mutex_lock(&gVid->videoBuffer_mutex);
+
+    memcpy(gVid->backBuffer, rgb, gVid->rgbBuffer_size);
+    hbuf = gVid->backBuffer;
+    gVid->backBuffer = gVid->frontBuffer;
+    gVid->frontBuffer = hbuf;
+
+    pthread_mutex_unlock(&gVid->videoBuffer_mutex);
+}
+
+
+void depth_cb(freenect_device *dev, freenect_depth *depth, uint32_t timestamp) {
+    int i;
+
+    for (i=0; i<gVid->depthWidth*gVid->depthHeight; i++) {
+        gVid->depthBuffer[i] = depth[i];
+    }
+}
+
+
+AR2VideoParamT* ar2VideoOpen(char *config_in ) {
+
+	AR2VideoParamT *vid = 0;
+	GError *error = 0;
+	char *config;
+
+	/* If no config string is supplied, we should use the environment variable, otherwise set a sane default */
+	if (!config_in || !(config_in[0])) {
+		/* None suppplied, lets see if the user supplied one from the shell */
+		char *envconf = getenv ("ARTOOLKIT_CONFIG");
+		if (envconf && envconf[0]) {
+			config = envconf;
+			g_printf ("Using config string from environment [%s].\n", envconf);
+		} else {
+			config = NULL;
+			g_printf ("No video config string supplied, using defaults.\n");
+		}
+	} else {
+		config = config_in;
+		g_printf ("Using supplied video config string [%s].\n", config_in);
+	}
+
+	/* init ART structure */
+    arMalloc( vid, AR2VideoParamT, 1 );
+
+    /* allocate the buffer */
+
+    vid->width = 640;
+    vid->height = 480;
+    vid->rgbBuffer_size = vid->width * vid->height * 3 * sizeof(ARUint8);
+    vid->backBuffer = (ARUint8*) malloc(vid->rgbBuffer_size);
+    vid->frontBuffer = (ARUint8*) malloc(vid->rgbBuffer_size);
+
+    vid->depthWidth = 640;
+    vid->depthHeight = 480;
+    vid->depthBuffer_size = vid->width * vid->height * sizeof(ARUint32);
+    vid->depthBuffer = (ARUint32*) malloc(vid->depthBuffer_size);
+
+    vid->streaming = FALSE;
+		
+	/* report the current version and features */
+	g_print ("libARvideo: libfreenect-0.0.1 init\n");
+
+    /* libfreenect init */
+    if (freenect_init(&(vid->f_ctx), NULL) < 0) {
+        g_error ("libARVideo: freenect_init() FAILED!\n");
+        printf("fail-init\n");
+    }
+
+    if (freenect_open_device(vid->f_ctx, &(vid->f_dev), 0) < 0) {
+        g_error("libARVideo: opening a kinect device FAILED!\n");
+        printf("fail-open\n");
+    }
+
+    //freenect_set_tilt_degs(vid->f_dev, 0);
+    freenect_set_led(vid->f_dev, LED_RED);
+    freenect_set_depth_callback(vid->f_dev, depth_cb);
+    freenect_set_rgb_callback(vid->f_dev, rgb_cb);
+    freenect_set_rgb_format(vid->f_dev, FREENECT_FORMAT_RGB);
+    freenect_set_depth_format(vid->f_dev, FREENECT_FORMAT_11_BIT);
+
+    pthread_mutex_init(&vid->videoBuffer_mutex, NULL);
+	
+	/* return the video handle */
+    gVid = vid;
+	return vid;
+}
+
+
+int ar2VideoClose(AR2VideoParamT *vid) {
+    freenect_set_led(vid->f_dev, LED_GREEN);
+    vid->streaming = FALSE;    
+	return 0;
+}
+
+
+ARUint8* ar2VideoGetImage(AR2VideoParamT *vid) {
+    ARUint8 *tb;
+	/* just return the bare video buffer */   
+    pthread_mutex_lock(&vid->videoBuffer_mutex);
+    tb = vid->frontBuffer;
+    pthread_mutex_unlock(&vid->videoBuffer_mutex);
+	return tb;
+}
+
+
+int ar2VideoCapStart(AR2VideoParamT *vid) {
+    vid->streaming = TRUE;
+    if ( pthread_create(&(vid->freenect_event_thread), NULL, freenect_threadfunc, NULL) ) {
+        g_error("libARVideo: creating thread FAILED!\n");
+    }
+    freenect_start_rgb(vid->f_dev);
+    freenect_start_depth(vid->f_dev);
+
+    return 0;
+}
+
+
+int ar2VideoCapStop(AR2VideoParamT *vid) {
+	/* stop pipeline */
+	g_error("libARVideo: can't stop streaming");
+}
+
+
+int ar2VideoCapNext(AR2VideoParamT *vid) {
+	/* gstreamer should */
+	return TRUE;
+}
+
+
+int ar2VideoInqSize(AR2VideoParamT *vid, int *x, int *y ) {
+   *x = vid->width; // width of your static image
+   *y = vid->height; // height of your static image
+}
+
+
+int ar2VideoInqDepthSize(AR2VideoParamT *vid, int *x, int *y ) {
+    *x = vid->depthWidth;
+    *y = vid->depthHeight;
+}
+
+ARUint32 *ar2VideoGetDepthImage(AR2VideoParamT* vid) {
+    return vid->depthBuffer;
+}
+
diff -Naur ARToolKit/lib/SRC/VideoOpenKinect/video.c.original ARToolKit-Freenect/lib/SRC/VideoOpenKinect/video.c.original
--- ARToolKit/lib/SRC/VideoOpenKinect/video.c.original	1970-01-01 01:00:00.000000000 +0100
+++ ARToolKit-Freenect/lib/SRC/VideoOpenKinect/video.c.original	2012-06-13 02:13:51.730618719 +0200
@@ -0,0 +1,466 @@
+/*
+ * Video capture module utilising the GStreamer pipeline for AR Toolkit
+ * 
+ * (c) Copyrights 2003-2007 Hartmut Seichter
+ * 
+ * licensed under the terms of the GPL v2.0
+ *
+ */
+
+/* include AR Toolkit*/ 
+#include <AR/config.h>
+#include <AR/ar.h>
+#include <AR/video.h>
+
+/* include GLib for GStreamer */
+#include <glib.h>
+
+/* include GStreamer itself */
+#include <gst/gst.h>
+
+/* using memcpy */
+#include <string.h>
+#include <pthread.h>
+
+#include <libfreenect.h>
+
+
+struct _AR2VideoParamT {
+
+	/* GStreamer pipeline */
+	GstElement *pipeline;
+	
+	/* GStreamer identity needed for probing */
+	GstElement *probe;
+	
+	/* size of the image */
+	int	width, height;
+
+	/* the actual video buffer 
+       double buffering is done in render part,
+        so simply lock and copy here */
+    ARUint8             *backBuffer;
+    ARUint8             *frontBuffer;
+    size_t              bufferSize;
+
+    /* freenect */
+    freenect_context *f_ctx;
+    freenect_device *f_dev;
+
+    pthread_mutex_t videoBuffer_mutex;
+    pthread_t freenect_event_thread;
+};
+
+
+static AR2VideoParamT *gVid = 0;
+
+static gboolean
+cb_have_data (GstPad    *pad,
+	      GstBuffer *buffer,
+	      gpointer   u_data)
+{
+ 	const GstCaps *caps;
+	GstStructure *str;
+	
+	gint width,height;
+	gdouble rate;
+	
+	AR2VideoParamT *vid = (AR2VideoParamT*)u_data;
+	
+
+	/* only do initialy for the buffer */
+	if (vid->backBuffer == 0) 
+	{ 
+	
+		/* 
+		 * Get the capabilities of the frame, we need that in order
+		 * to extract information about the frame 
+		 */
+		caps=gst_pad_get_negotiated_caps(pad);
+		str=gst_caps_get_structure(caps,0);
+
+		/* Get some data about the frame */
+		gst_structure_get_int(str,"width",&width);
+		gst_structure_get_int(str,"height",&height);
+		gst_structure_get_double(str,"framerate",&rate);
+		
+		g_print("libARvideo: GStreamer negotiated %dx%d\n",width,height);
+	
+		vid->width = width;
+		vid->height = height;
+		
+		/* allocate the buffer */
+		vid->backBuffer = malloc(buffer->size);
+		vid->frontBuffer = malloc(buffer->size);
+        vid->bufferSize = buffer->size;
+		
+		return TRUE;
+		
+	}
+	else 
+	{
+		/* copy the video buffer */
+        pthread_mutex_lock(&vid->videoBuffer_mutex);
+		memcpy(vid->backBuffer, buffer->data, buffer->size);
+        pthread_mutex_unlock(&vid->videoBuffer_mutex);
+	}	
+	
+	return TRUE;
+}
+
+void 
+testing_pad(GstPad *pad)
+{		
+	const GstCaps *caps;
+	GstStructure *str;
+	
+	gint width,height;
+	gdouble rate;
+
+	caps=gst_pad_get_negotiated_caps(pad);
+
+	if (caps) {
+		str=gst_caps_get_structure(caps,0);
+
+		/* Get some data about the frame */
+		gst_structure_get_int(str,"width",&width);
+		gst_structure_get_int(str,"height",&height);
+		gst_structure_get_double(str,"framerate",&rate);
+		
+		g_print("libARvideo: GStreamer negotiated %dx%d\n",width,height);
+	} else {
+		return;
+#if 0		
+		g_print("Nothing yet!");	
+#endif
+
+	}
+}
+
+
+int
+arVideoOpen( char *config ) {
+   if( gVid != NULL ) {
+        printf("Device has been opened!!\n");
+        return -1;
+    }
+    gVid = ar2VideoOpen( config );
+    if( gVid == NULL ) return -1;
+}
+
+int 
+arVideoClose( void )
+{
+	return ar2VideoClose(gVid);
+}
+
+int
+arVideoDispOption( void )
+{
+   return 0;
+}
+
+int
+arVideoInqSize( int *x, int *y ) {
+	
+	ar2VideoInqSize(gVid,x,y);
+
+	return 0;
+}
+
+ARUint8
+*arVideoGetImage( void )
+{
+   return ar2VideoGetImage(gVid);  // address of your image data
+}
+
+int 
+arVideoCapStart( void ) {
+
+	ar2VideoCapStart(gVid);
+	return 0;
+}
+
+int 
+arVideoCapStop( void )
+{
+	ar2VideoCapStop(gVid);
+	return 0;
+}
+
+int arVideoCapNext( void )
+{
+	ar2VideoCapNext(gVid);
+	return 0;
+}
+
+/*---------------------------------------------------------------------------*/
+
+
+void *freenect_threadfunc(void *arg) {
+    printf("START OF FREENECT THREAD\n");
+    while (freenect_process_events(gVid->f_ctx) >= 0);
+    printf("END OF FREENECT THREAD\n");
+}
+
+void rgb_cb(freenect_device *dev, freenect_pixel *rgb, uint32_t timestamp) {
+    int i;
+    freenect_pixel *kp = rgb;
+    ARUint8 *arp;
+
+    if (!gVid->frontBuffer) return;
+
+    pthread_mutex_lock(&gVid->videoBuffer_mutex);
+    arp = gVid->frontBuffer;
+    for(i=0; i<gVid->width*gVid->height; i++) {
+        *arp = *kp; arp++; kp++;
+        *arp = *kp; arp++; kp++;
+        *arp = *kp; arp++; kp++;
+    }
+    pthread_mutex_unlock(&gVid->videoBuffer_mutex);
+
+    printf("copied frame");
+}
+
+AR2VideoParamT* 
+ar2VideoOpen(char *config_in ) {
+
+	AR2VideoParamT *vid = 0;
+	GError *error = 0;
+	int i;
+	GstPad *pad, *peerpad;
+	GstXML *xml;
+	GstStateChangeReturn _ret;
+	char *config;
+
+	/* If no config string is supplied, we should use the environment variable, otherwise set a sane default */
+	if (!config_in || !(config_in[0])) {
+		/* None suppplied, lets see if the user supplied one from the shell */
+		char *envconf = getenv ("ARTOOLKIT_CONFIG");
+		if (envconf && envconf[0]) {
+			config = envconf;
+			g_printf ("Using config string from environment [%s].\n", envconf);
+		} else {
+			config = NULL;
+			g_printf ("No video config string supplied, using defaults.\n");
+		}
+	} else {
+		config = config_in;
+		g_printf ("Using supplied video config string [%s].\n", config_in);
+	}
+
+	/* initialise GStreamer */
+	gst_init(0,0);	
+	
+	/* init ART structure */
+    arMalloc( vid, AR2VideoParamT, 1 );
+
+	/* initialise buffer */
+	vid->backBuffer = 0;
+	
+	/* report the current version and features */
+	g_print ("libARvideo: %s\n", gst_version_string());
+
+#if 0	
+	xml = gst_xml_new();
+	
+	/* first check if config contains an xml file */
+	if (gst_xml_parse_file(xml,config,NULL)) 
+	{
+		/* parse the pipe definition */
+		
+	} else 
+	{
+		vid->pipeline = gst_xml_get_element(xml,"pipeline");
+	}
+	
+#endif
+
+	vid->pipeline = gst_parse_launch (config, &error);
+	
+	if (!vid->pipeline) {
+		g_print ("Parse error: %s\n", error->message);
+		return 0;
+	};
+
+	/* get the video sink */
+	vid->probe = gst_bin_get_by_name(GST_BIN(vid->pipeline), "artoolkit");
+
+	if (!vid->probe) {
+		g_print("Pipeline has no element named 'artoolkit'!\n");
+		return 0;	
+	};
+		
+	/* get the pad from the probe (the source pad seems to be more flexible) */	
+	pad = gst_element_get_pad (vid->probe, "src");
+
+		
+	/* install the probe callback for capturing */
+	gst_pad_add_buffer_probe (pad, G_CALLBACK (cb_have_data), vid);	
+	
+	
+
+#if 0
+	/* request ready state */
+	gst_element_set_state (vid->pipeline, GST_STATE_READY);
+	
+	/* check if stream is ready */
+	if (gst_element_get_state (vid->pipeline, NULL, NULL, -1) == GST_STATE_CHANGE_FAILURE) {
+    	g_error ("libARvideo: failed to put GStreamer into READY state!\n");
+    } else {
+    	g_print ("libARvideo: GStreamer pipeline is READY!\n");
+    }
+#endif
+
+	/* Needed to fill the information for ARVidInfo */
+	gst_element_set_state (vid->pipeline, GST_STATE_PAUSED);
+
+	peerpad = gst_pad_get_peer(pad);
+	
+	testing_pad(peerpad);
+
+	/* dismiss the pad */
+	gst_object_unref (pad);
+	
+	/* wait until it's up and running or failed */
+	if (gst_element_get_state (vid->pipeline, NULL, NULL, -1) == GST_STATE_CHANGE_FAILURE) {
+    	g_error ("libARvideo: failed to put GStreamer into PAUSE state!\n");
+    } else {
+    	g_print ("libARvideo: GStreamer pipeline is PAUSED!\n");
+    }
+
+	/* now preroll for V4L v2 interfaces */
+	if ((strstr(config, "v4l2src") != 0) ||
+		(strstr(config, "dv1394src") != 0))
+	{
+		/* set playing state of the pipeline */
+		gst_element_set_state (vid->pipeline, GST_STATE_PLAYING);
+		
+		/* wait until it's up and running or failed */
+		if (gst_element_get_state (vid->pipeline, NULL, NULL, -1) == GST_STATE_CHANGE_FAILURE) {
+	    	g_error ("libARvideo: failed to put GStreamer into PLAYING state!\n");
+	    } else {
+	    	g_print ("libARvideo: GStreamer pipeline is PLAYING!\n");
+	    }
+		
+		/* set playing state of the pipeline */
+		gst_element_set_state (vid->pipeline, GST_STATE_PAUSED);
+		
+		/* wait until it's up and running or failed */
+		if (gst_element_get_state (vid->pipeline, NULL, NULL, -1) == GST_STATE_CHANGE_FAILURE) {
+	    	g_error ("libARvideo: failed to put GStreamer into PAUSED state!\n");
+	    } else {
+	    	g_print ("libARvideo: GStreamer pipeline is PAUSED!\n");
+	    }
+	}
+		
+#if 0
+	/* write the bin to stdout */
+	gst_xml_write_file (GST_ELEMENT (vid->pipeline), stdout);
+#endif
+
+    printf("my code\n");
+
+    /* libfreenect init */
+    if (freenect_init(&(vid->f_ctx), NULL) < 0) {
+        g_error ("libARVideo: freenect_init() FAILED!\n");
+        printf("fail-init\n");
+    }
+
+    if (freenect_open_device(vid->f_ctx, &(vid->f_dev), 0) < 0) {
+        g_error("libARVideo: opening a kinect device FAILED!\n");
+        printf("fail-open\n");
+    }
+
+    //freenect_set_tilt_degs(vid->f_dev, 0);
+    freenect_set_led(vid->f_dev, LED_RED);
+    //freenect_set_depth_callback(vid->f_dev, depth_cb);
+    freenect_set_rgb_callback(vid->f_dev, rgb_cb);
+    freenect_set_rgb_format(vid->f_dev, FREENECT_FORMAT_RGB);
+    freenect_set_depth_format(vid->f_dev, FREENECT_FORMAT_11_BIT);
+
+    gVid = vid;
+
+    pthread_mutex_init(&vid->videoBuffer_mutex, NULL);
+    if ( pthread_create(&(vid->freenect_event_thread), NULL, freenect_threadfunc, NULL) ) {
+        g_error("libARVideo: creating thread FAILED!\n");
+    }
+
+    freenect_start_rgb(vid->f_dev);
+	
+	/* return the video handle */
+	return vid;
+}
+
+
+int 
+ar2VideoClose(AR2VideoParamT *vid) {
+	/* stop the pipeline */
+	gst_element_set_state (vid->pipeline, GST_STATE_NULL);
+	/* free the pipeline handle */
+	gst_object_unref (GST_OBJECT (vid->pipeline));
+
+	return 0;
+}
+
+
+ARUint8* 
+ar2VideoGetImage(AR2VideoParamT *vid) {
+    ARUint8 *hbuf;    
+
+    pthread_mutex_lock(&vid->videoBuffer_mutex);
+    //hbuf = vid->backBuffer;
+    //vid->backBuffer = vid->frontBuffer;
+    //vid->frontBuffer = hbuf;
+    pthread_mutex_unlock(&vid->videoBuffer_mutex);
+
+	/* just return the bare video buffer */   
+	return vid->frontBuffer;
+}
+
+int 
+ar2VideoCapStart(AR2VideoParamT *vid) 
+{
+	GstStateChangeReturn _ret;
+
+	/* set playing state of the pipeline */
+	_ret = gst_element_set_state (vid->pipeline, GST_STATE_PLAYING);
+
+	if (_ret == GST_STATE_CHANGE_ASYNC) 
+	{
+
+		/* wait until it's up and running or failed */
+		if (gst_element_get_state (vid->pipeline, 
+				NULL, NULL, GST_CLOCK_TIME_NONE) == GST_STATE_CHANGE_FAILURE) 
+		{
+    		g_error ("libARvideo: failed to put GStreamer into PLAYING state!\n");    	
+    		return 0;
+  
+        } else {
+			g_print ("libARvideo: GStreamer pipeline is PLAYING!\n");
+		} 
+	}
+	return 1; 
+}
+
+int 
+ar2VideoCapStop(AR2VideoParamT *vid) {
+	/* stop pipeline */
+	return gst_element_set_state (vid->pipeline, GST_STATE_NULL);
+}
+
+int 
+ar2VideoCapNext(AR2VideoParamT *vid)
+{
+	/* gstreamer should */
+	return TRUE;
+}
+
+int
+ar2VideoInqSize(AR2VideoParamT *vid, int *x, int *y ) 
+{
+
+   *x = vid->width; // width of your static image
+   *y = vid->height; // height of your static image
+
+}
diff -Naur ARToolKit/util/calib_camera2/main.c ARToolKit-Freenect/util/calib_camera2/main.c
--- ARToolKit/util/calib_camera2/main.c	2006-10-03 23:35:27.000000000 +0200
+++ ARToolKit-Freenect/util/calib_camera2/main.c	2012-06-13 02:57:43.882654523 +0200
@@ -61,7 +61,9 @@
 static char            *vconf = "-size=FULL";
 #elif defined(__linux)
 #  if defined(AR_INPUT_GSTREAMER)
-char 			*vconf = "videotestsrc ! capsfilter caps=video/x-raw-rgb,bpp=24 ! identity name=artoolkit ! fakesink";
+char 			*vconf = "";
+#  elif defined(AR_INPUT_OPENKINECT)
+char 			*vconf = "";
 #  elif defined(AR_INPUT_V4L)
 static char            *vconf = "-width=640 -height=480";
 #  elif defined(AR_INPUT_1394CAM)
diff -Naur ARToolKit/util/calib_cparam/calib_cparam.c ARToolKit-Freenect/util/calib_cparam/calib_cparam.c
--- ARToolKit/util/calib_cparam/calib_cparam.c	2006-09-15 05:08:18.000000000 +0200
+++ ARToolKit-Freenect/util/calib_cparam/calib_cparam.c	2012-06-13 02:57:15.810656017 +0200
@@ -61,7 +61,9 @@
 char            *vconf = "-size=FULL";
 #elif defined(__linux)
 #  if defined(AR_INPUT_GSTREAMER)
-char 			*vconf = "videotestsrc";
+char 			*vconf = "";
+#  elif defined(AR_INPUT_OPENKINECT)
+char 			*vconf = "";
 #  elif defined(AR_INPUT_V4L)
 char            *vconf = "-width=640 -height=480";
 #  elif defined(AR_INPUT_1394CAM)
diff -Naur ARToolKit/util/calib_distortion/calib_dist.c ARToolKit-Freenect/util/calib_distortion/calib_dist.c
--- ARToolKit/util/calib_distortion/calib_dist.c	2006-10-03 23:35:19.000000000 +0200
+++ ARToolKit-Freenect/util/calib_distortion/calib_dist.c	2012-06-13 02:13:51.738618437 +0200
@@ -61,7 +61,9 @@
 char            *vconf = "-size=FULL";
 #elif defined(__linux)
 #  if defined(AR_INPUT_GSTREAMER)
-char 			*vconf = "videotestsrc";
+char 			*vconf = "";
+#  elif defined(AR_INPUT_OPENKINECT)
+char 			*vconf = "";
 #  elif defined(AR_INPUT_V4L)
 char            *vconf = "-width=640 -height=480";
 #  elif defined(AR_INPUT_1394CAM)
diff -Naur ARToolKit/util/mk_patt/mk_patt.c ARToolKit-Freenect/util/mk_patt/mk_patt.c
--- ARToolKit/util/mk_patt/mk_patt.c	2006-09-15 05:08:18.000000000 +0200
+++ ARToolKit-Freenect/util/mk_patt/mk_patt.c	2012-06-13 02:58:06.354654764 +0200
@@ -58,7 +58,9 @@
 char            *vconf = "-size=FULL";
 #elif defined(__linux)
 #  if defined(AR_INPUT_GSTREAMER)
-char 			*vconf = "videotestsrc";
+char 			*vconf = "";
+#  elif defined(AR_INPUT_OPENKINECT)
+char 			*vconf = "";
 #  elif defined(AR_INPUT_V4L)
 char            *vconf = "-width=640 -height=480";
 #  elif defined(AR_INPUT_1394CAM)
